# 📚 Generative AI Lecture 2025
This repository contains organized notebooks and lecture materials covering various topics in Generative AI and Large Language Models (LLMs). It is structured to support both foundational theory and practical implementations, including specific focus on BERT and GPT-2.
## 📁 Folder Structure
```
Generative AI lecture 2025/
├── GenAI/
│   └── GenerativeAI.ipynb
├── LLMs/
│   ├── LLM_theory.ipynb
│   ├── BERT/
│   │   └── vertopal_BERT.ipynb
│   └── GPT-2/
│       └── vertopal.com_GPT_2.ipynb
```
## 📂 Main Topics
### GenAI
Contains theoretical and practical explorations of general generative AI models.

[GenerativeAI.ipynb]

- Covers VAEs, GANs, Diffusion Models

- Includes PyTorch implementations for VAE and GAN on MNIST digits

- Compares various generative architectures and their use cases
### LLMs
Focuses on transformer-based language models and fine-tuning practices.

[LLM_theory.ipynb]

- Introduces Transformer architecture and key components (Q, K, V, Attention, etc.)

- Details GPT, BERT, BART architectures

- Explains encoder, decoder layers, and model directionality

- Includes summary of fine-tuning strategies for different tasks

## ✅ Dependencies
Most notebooks use the following Python packages:
- transformers
- datasets
- torch
- pandas
- matplotlib
- bitsandbytes
- trl
- accelerate
### ✍️ Author
Prepared by Hai Nguyen Ngoc
2025 – For lecture and academic study purposes.





